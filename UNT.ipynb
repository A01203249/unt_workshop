{"cells":[{"cell_type":"markdown","source":["# Non Cognitive Factors of Learning\n\nIn the scopre of academic performance, Non Cognitive factors are concepts such as learners' academic behaviors, academic perseverance, academic mindsets, learning strategies and social skills, etc.\nIn this notebook we will be exporing one of such factors called confidence. We will be using question level data with student self reported confidence.\nDuring this hands on tutorial, we will do the follow:\n\n* Create fake data for exploration (b/c real data comes with privacy concerns)\n* Develop features/variables that we will be analyzing\n* Visualize the results"],"metadata":{}},{"cell_type":"code","source":["#read in the necessary libraries (libraries are packages of functions that help us reuce code instead of recreating and repeating)\nimport numpy as np\nimport pandas as pd\nimport random\nimport matplotlib.mlab as mlab\nimport matplotlib.pyplot as plt"],"metadata":{},"outputs":[],"execution_count":2},{"cell_type":"markdown","source":["## I. Creating Fake Data\n\nWe will create data which represents a student answering a question. The data has the following attributes:\n\n* user_id: unique to the student\n* question_id: unique to the question\n* prescore: [0-3] and represents the students' self reported confidence\n  * 0: No idea\n  * 1: Unsure\n  * 2: Think so\n  * 3: I know it\n* postscore: [0-1] and represents if the student got the question wrong [0] or right [1]\n\n\n### 1. Uniform random number\nWe will start with a simple uniform random number for generating both the prescore and postscore data."],"metadata":{}},{"cell_type":"code","source":["#fake data via random number generation with conditions but no weights\nresults_i = []\nfor student in range(100):\n  for question in range(100):\n    user_id = student\n    question_id = question\n    prescore = random.randint(0,3)\n    postscore = random.randint(0,1)\n    student_question = (user_id, question_id, prescore, postscore)\n    results_i.append(student_question)"],"metadata":{},"outputs":[],"execution_count":4},{"cell_type":"code","source":["#see inside the dataFrame\nresults_i"],"metadata":{},"outputs":[],"execution_count":5},{"cell_type":"code","source":["#convert the list into a dataframe and assign columns (we won't be using this until cell 20)\nresults_i_df = pd.DataFrame(results_i, columns = ('user_id', 'question_id', 'confidence', 'score'))\nresults_i_df"],"metadata":{},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":["### II. Weighted random number generator\nWe will now create weighted random numbers and re-compute the data. Here we can use the probabilities from the real data\n\n#### 1. Weighted prescore\nFor a weighted random number r, the prescore is defined as\n\n* 0  < r < c1\n  * prescore = 0\n* c1 < r < c2\n  * prescore = 1\n* c2 < r < c3\n  * prescore = 2\n* c3 < r < 1\n  * prescore = 3\n  \nWith c1=0.05, c2=0.1, and c3=0.3.\n\nThis means the data should have the distribution of 0 (5%), 1 (5%), 2 (20%), 3 (70%) which mimicks the real data.\n\n#### 2. Weighted postscore\nIn a similar way, we create weighted postscores with the distribution of 0 (40%) and 1 (60%)."],"metadata":{}},{"cell_type":"code","source":["#fake data via random number generation with conditions and weighted distribution\ndef weighted_prescore():\n  cutoff1 = 0.05\n  cutoff2 = 0.1\n  cutoff3 = 0.3\n\n  randy = random.random()\n  if randy < cutoff1:\n    return 0\n  elif randy < cutoff2:\n    return 1\n  elif randy < cutoff3:\n    return 2\n  else:\n    return 3\n  \ndef weighted_postscore():\n  cutoff1 = .4\n  \n  randy = random.random()\n  if randy < cutoff1:\n    return 0\n  else:\n    return 1\n  \nresults = []\nfor student in range(100):\n  for question in range(100):\n    user_id = student\n    question_id = question\n    prescore = weighted_prescore()\n    postscore = weighted_postscore()\n    student_question = (user_id, question_id, prescore, postscore)\n    results.append(student_question)\n    \nresults"],"metadata":{},"outputs":[],"execution_count":8},{"cell_type":"markdown","source":["## Exercise: what weights would you assign to create data that has\nprescore 0 = 5% \nprescore 1 = 10%\nprescore 2 = 30%\nprescore 3 = 55%"],"metadata":{}},{"cell_type":"code","source":["#your code goes here"],"metadata":{},"outputs":[],"execution_count":10},{"cell_type":"code","source":["#double check the type of your new object\ntype(results)"],"metadata":{},"outputs":[],"execution_count":11},{"cell_type":"code","source":["#convert the list into dataframe and assign column names\nresults_df = pd.DataFrame(results, columns = ('user_id', 'question_id', 'confidence', 'score'))\nresults_df"],"metadata":{},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":["![Confidence_profiles](files/images.jpg)"],"metadata":{}},{"cell_type":"code","source":["![Confidence](https://octodex.github.com/images/yaktocat.png)"],"metadata":{},"outputs":[],"execution_count":14},{"cell_type":"code","source":["#add another column to the dataframe with conditions for overconfidence and underconfidence (see the ppt slide 11)\nresults_df['conf_profile'] = np.where(((results_df.confidence == 0) | (results_df.confidence == 1)) & (results_df.score == 1), 'underconf', \n                                   np.where(((results_df.confidence == 2) | (results_df.confidence == 3)) & (results_df.score == 0), 'overconf', 'other'))\nprint(results_df)"],"metadata":{},"outputs":[],"execution_count":15},{"cell_type":"code","source":["#create a column for the count of underconfidence instances\nresults_df['uconf'] = np.where(results_df['conf_profile'] == 'underconf', 1, 0)\nresults_df"],"metadata":{},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":["## Exercise: using confidence and score columns, create a boolean column like overconf or uconf and name it 'knowledgeable'. This column will be populated with 1 only when confidnce = 3 and score = 1. Otherwise it will have a value of 0."],"metadata":{}},{"cell_type":"code","source":["#your code goes here"],"metadata":{},"outputs":[],"execution_count":18},{"cell_type":"code","source":["#create a column for the count of overconfidence instances\nresults_df['overconf'] = np.where(results_df['conf_profile'] == 'overconf', 1, 0)\nresults_df"],"metadata":{},"outputs":[],"execution_count":19},{"cell_type":"markdown","source":["## Aggregations in panda. \n\nKey functions to know is groupby which groups your data based on the column you select.\nAggregation, which aggregates by the operation you select: sum, count, mean, etc.\nJoin, joins all your columns back into one dataframe"],"metadata":{}},{"cell_type":"code","source":["#aggregate the data from question level to user level\ndf = results_df.groupby('user_id')\ncounts = df.size().to_frame(name='ques_count')\nagg_results_final = (counts\n .join(df.agg({'confidence': 'mean'}).rename(columns={'confidence': 'avg_conf'}))\n .join(df.agg({'score': 'sum'}).rename(columns={'score': '#correct_answs'}))\n .join(df.agg({'overconf': 'sum'}).rename(columns={'overconf': '#overconf'}))\n .join(df.agg({'uconf': 'sum'}).rename(columns={'uconf': '#underconf'}))\n .reset_index()\n)\n\nagg_results_final"],"metadata":{},"outputs":[],"execution_count":21},{"cell_type":"markdown","source":["##Plotting: Histograms"],"metadata":{}},{"cell_type":"code","source":["#plot distribution of confidence from uniform distribution (see slide 7)\nf,ax = plt.subplots()\nbins = [-0.5, 0.5,1.5,2.5,3.5,4.5]\nplt.hist(results_i_df['confidence'], bins = bins, facecolor='green', alpha=0.5)\nplt.xticks(range(0,4))\nplt.xlim([-1,4])\nplt.xlabel('Confidence Score', fontsize=14)\nplt.ylabel('Number of Questions', fontsize=14)\nplt.title('Question Confidence\\n Uniform Random Numbers', fontsize=16)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":23},{"cell_type":"code","source":["#plot distribution of confidence from probability distribution (see slide 7)\nf,ax = plt.subplots()\nbins = [-0.5, 0.5,1.5,2.5,3.5,4.5]\nplt.hist(results_df['confidence'], bins = bins, facecolor='green', alpha=0.5)\nplt.xticks(range(0,4))\nplt.xlim([-1,4])\nplt.xlabel('Confidence Score', fontsize=14)\nplt.ylabel('Number of Questions', fontsize=14)\nplt.title('Question Confidence\\n Weighted Random Numbers', fontsize=16)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":24},{"cell_type":"markdown","source":["###Exercise: Plot distribution of scores both for random data and for probability distribution"],"metadata":{}},{"cell_type":"code","source":["#your code goes here"],"metadata":{},"outputs":[],"execution_count":26},{"cell_type":"markdown","source":["##Correlations show the relationship (negative or positive, strong or weak) between the variables you choose. For example, how correlated is student's midterm grade with their final grade."],"metadata":{}},{"cell_type":"code","source":[""],"metadata":{},"outputs":[],"execution_count":28},{"cell_type":"code","source":["#calculate correlation between average confidence and accuracy (see slide 14)\nagg_results_final['avg_conf'].corr(agg_results_final['#correct_answs'])"],"metadata":{},"outputs":[],"execution_count":29},{"cell_type":"code","source":["#your code goes here\ndata = agg_results_final[['avg_conf','#correct_answs']]\ncorrelation = data.corr(method='pearson')\ncorrelation"],"metadata":{},"outputs":[],"execution_count":30},{"cell_type":"markdown","source":["### Exercise: calculate Pearson correlation between two other values that you find meaningful."],"metadata":{}},{"cell_type":"code","source":["#your code goes here"],"metadata":{},"outputs":[],"execution_count":32},{"cell_type":"markdown","source":["## Time series\n\n* Group question level df by question index\n* Find counts of confidence profiles for the question level group\n* Find total number of questions for question level group\n* Find % of questions in each conf profile for question level group\n* Plot x -> question index vs y -> (%uc, %oc, %k, %r)"],"metadata":{}},{"cell_type":"markdown","source":["## Confidence profiles from uniformly generated random data"],"metadata":{}},{"cell_type":"code","source":["question_index = range(0,100)\nper_u_c = random.sample(xrange(100), 100)\nper_o_c = random.sample(xrange(100), 100)\nper_k = random.sample(xrange(100), 100)\nper_r = random.sample(xrange(100), 100)\n\n\nf,ax = plt.subplots()\nax.plot(question_index, per_u_c, 'g-', label='underconf')\nax.plot(question_index, per_o_c, 'r-', label='overconf')\nax.plot(question_index, per_k, 'y-', label='knowledgable')\nax.plot(question_index, per_r, 'b-', label='realistic')\nax.legend(loc='best')\ndisplay()"],"metadata":{},"outputs":[],"execution_count":35},{"cell_type":"markdown","source":["## Confidence profiles from weighted random generation of data"],"metadata":{}},{"cell_type":"code","source":["prc_df = results_df.groupby('question_id').agg({'overconf':'sum', 'uconf':'sum'}).reset_index()\n\n# f = {'overconf':['sum'], 'uconf': lambda g: results_df.ix[g.index].uconf.sum() * 100/ 100}\n# percent_df = results_df.groupby('question_id').agg(f).reset_index()\n\n# prc_df['perc_u'] = time_df['overconf']\n# prc_df['perc_o'] = time_df['uconf']"],"metadata":{},"outputs":[],"execution_count":37},{"cell_type":"code","source":["prc_df"],"metadata":{},"outputs":[],"execution_count":38},{"cell_type":"code","source":["question_index = range(0,100)\nper_uc = prc_df['uconf']\nper_oc = prc_df['overconf']\n#per_k = random.sample(xrange(100), 100)\n#per_r = random.sample(xrange(100), 100)\n\nf,ax = plt.subplots()\nax.plot(question_index, per_uc, 'g-', label='Underconf')\nax.plot(question_index, per_oc, 'r-', label='Overconf')\n# ax.plot(question_index, per_k, 'y-', label='knowledgable')\n# ax.plot(question_index, per_r, 'b-', label='realistic')\nax.legend(loc='best')\nplt.xlabel('Percent Questions', fontsize=14)\nplt.ylabel('Questions in Order', fontsize=14)\nplt.title('Confidence profiles Overtime', fontsize=16)\ndisplay()"],"metadata":{},"outputs":[],"execution_count":39}],"metadata":{"name":"UNT","notebookId":373828},"nbformat":4,"nbformat_minor":0}
